{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README.\n",
    "\n",
    "This notebook is the entrypoint for Azure ML enabled evaluation of trained Neural Networks.\n",
    "In its essence, it connects to Azure ML, makes sure that everything is ready over there, and starts the evaluation.\n",
    "To that end, this notebook gathers all necessary sourcecodes in a temp-folder, which will be pushed to Azure ML for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Experiment\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create temp folder and copy code.\n",
    "\n",
    "Here you have to be very precise, which code to copy.\n",
    "And most importantly, which code NOT to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp folder...\n",
      "Copying files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating temp folder...\")\n",
    "temp_path = \"tmp_evaluate\"\n",
    "if os.path.exists(temp_path):\n",
    "    shutil.rmtree(temp_path)\n",
    "os.mkdir(temp_path)\n",
    "\n",
    "print(\"Copying files...\")\n",
    "shutil.copy(os.path.join(\"code\", \"evaluate.py\"), temp_path)\n",
    "shutil.copy(os.path.join(\"code\", \"preprocessing.py\"), temp_path)\n",
    "shutil.copytree(os.path.join(\"code\", \"gapnet\"), os.path.join(temp_path, \"gapnet\"))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to azure workspace.\n",
    "\n",
    "Make sure that you have a config.json file with the keys subscription_id, resource_group, and cgm-ml-dev. Either here (not so nice) or in a parent folder (okay but not perfect), or in the root folder of this repo (way to go)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='cgm-ml-dev', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-dev')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = Workspace.from_config()\n",
    "workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the experiment.\n",
    "\n",
    "- You should always arrange all your runs in an experiment.\n",
    "- Create at least one experiment per sprint.\n",
    "- Make sure that the name of the experiment reflects the sprint number.\n",
    "- On top of that you could also add other tokens to the name. For example network architecture, dataset name, and/or targets.# Get the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>s2-gapnet-height</td><td>cgm-ml-dev</td><td><a href=\"https://ml.azure.com/experiments/s2-gapnet-height?wsid=/subscriptions/9b82ecea-6780-4b85-8acf-d27d79028f07/resourcegroups/cgm-ml-dev/workspaces/cgm-ml-dev\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: s2-gapnet-height,\n",
       "Workspace: cgm-ml-dev)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = \"s2-gapnet-height\"\n",
    "experiment = Experiment(workspace=workspace, name=experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find/create a compute target.\n",
    "\n",
    "Connects to a compute cluster on Azure ML.\n",
    "If the compute cluster does not exist, it will be created.\n",
    "\n",
    "Note: Usually computer clusters autoscale. This means that new nodes are created when necessary. And unused VMs will be shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AmlCompute(workspace=Workspace.create(name='cgm-ml-dev', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-dev'), name=tristan-gpu, id=/subscriptions/9b82ecea-6780-4b85-8acf-d27d79028f07/resourceGroups/cgm-ml-dev/providers/Microsoft.MachineLearningServices/workspaces/cgm-ml-dev/computes/tristan-gpu, type=AmlCompute, provisioning_state=Succeeded, location=westeurope, tags=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "import azureml\n",
    " \n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"tristan-gpu\"\n",
    "\n",
    "# Compute cluster exists. Just connect to it.\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "\n",
    "# Compute cluster does not exist. Create one.    \n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC6', \n",
    "        max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset for evaluation.\n",
    "\n",
    "Here you specify which dataset to use.\n",
    "\n",
    "Note: Double check on Azure ML that you are using the right one.\n",
    "\n",
    "Note: This dataset is not necessarily the one you used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('premiumfileshare', '2019_11_14-bmz_prod_uncleaned/**')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"25493ad0-44b0-4772-a3d4-bf6bd8d44662\",\n",
       "    \"name\": \"2019_11_14-bmz_prod_uncleaned\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='cgm-ml-dev', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-dev')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_name = \"cgmmldevpremium-SampleDataset-Example\" # Tiny dataset.\n",
    "dataset_name = \"2019_11_14-bmz_prod_uncleaned\" # Full dataset.\n",
    "dataset = workspace.datasets[dataset_name]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the run that contains the trained model.\n",
    "\n",
    "Make super sure that you put the right experiment- and run-id here.\n",
    "Double check with Azure ML.\n",
    "The evaluation script will grab the model as a binary file from that run and use it for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"s1-gapnet-height\"\n",
    "run_id = \"s1-gapnet-weight_1579792118_0c294b2b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push the evaluation source code to Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.10', '1.12', '1.13', '2.0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "TensorFlow.get_supported_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd106eae002e40dda3be8461a1541e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Queued\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/s2-gapnet-height/runs/s2-gapnet-height_1580890382_3df09db4?wsid=/subscriptions/9b82ecea-6780-4b85-8acf-d27d79028f07/resourcegroups/cgm-ml-dev/workspaces/cgm-ml-dev\", \"run_id\": \"s2-gapnet-height_1580890382_3df09db4\", \"run_properties\": {\"run_id\": \"s2-gapnet-height_1580890382_3df09db4\", \"created_utc\": \"2020-02-05T08:13:05.112055Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"a2e3e228-0fe2-4cf4-b9d0-7ba8b5a07de7\", \"azureml.git.repository_uri\": \"https://cgmwhh@dev.azure.com/cgmwhh/ChildGrowthMonitor/_git/cgm-ml-service\", \"mlflow.source.git.repoURL\": \"https://cgmwhh@dev.azure.com/cgmwhh/ChildGrowthMonitor/_git/cgm-ml-service\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"1903aa083f87599373021129f8b0d047f0857764\", \"mlflow.source.git.commit\": \"1903aa083f87599373021129f8b0d047f0857764\", \"azureml.git.dirty\": \"True\", \"AzureML.DerivedImageName\": \"azureml/azureml_a2ee7178ea2851beb3a587e36b64323d\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":1,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Queued\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:05:02\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify pip packages here.\n",
    "pip_packages = [\n",
    "    \"azureml-dataprep[fuse,pandas]\",\n",
    "    \"glob2\"\n",
    "]\n",
    "\n",
    "# Specify script parameters. Most importantly, the id of the run that contains the model.\n",
    "script_params = {\n",
    "    \"--experiment_name\": experiment_name, # The experiment that contains the model.\n",
    "    \"--run_id\": run_id # The run that contains the model.\n",
    "}\n",
    "\n",
    "# Create the estimator.\n",
    "estimator = TensorFlow(\n",
    "    source_directory=temp_path,\n",
    "    compute_target=compute_target,\n",
    "    entry_script=\"evaluate.py\",\n",
    "    script_params=script_params,\n",
    "    use_gpu=True,\n",
    "    framework_version=\"2.0\",\n",
    "    inputs=[dataset.as_named_input(\"dataset\").as_mount()],\n",
    "    pip_packages=pip_packages\n",
    ")\n",
    "\n",
    "# Set compute target.\n",
    "estimator.run_config.target = compute_target\n",
    "\n",
    "# Run the experiment.\n",
    "run = experiment.submit(estimator)\n",
    "\n",
    "# Show outpus.\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete temp folder.\n",
    "\n",
    "After all code has been pushed to Azure ML, the temp folder will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_path)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
