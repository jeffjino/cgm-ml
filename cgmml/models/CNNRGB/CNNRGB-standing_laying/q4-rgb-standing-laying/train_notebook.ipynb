{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# README.\n",
    "\n",
    "This notebook is the entrypoint for Azure ML enabled training.\n",
    "In its essence, it connects to Azure ML, makes sure that everything is ready over there, and starts the training.\n",
    "To that end, this notebook gathers all necessary sourcecodes in a temp-folder, which will be pushed to Azure ML for training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import glob2 as glob\n",
    "from azureml.core import Dataset, Experiment, Environment, Run, ScriptRunConfig, Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "from src.sl_constants import REPO_DIR\n",
    "from src.sl_config import CONFIG, DATASET_MODE_MOUNT, DATASET_MODE_DOWNLOAD\n",
    "# from src.train_util import copy_dir"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting screws"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_name = \"anon-rgb-classification\"  # \"anon-depthmap-mini\"\n",
    "experiment_name = \"q4-rgb-plaincnn-classifaction-standing-lying-8k\"\n",
    "tags = {}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create temp folder and copy code.\n",
    "\n",
    "Here you have to be very precise, which code to copy.\n",
    "And most importantly, which code NOT to copy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "code_dir = \"src\"\n",
    "paths = glob.glob(os.path.join(code_dir, \"*.py\"))\n",
    "paths"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Creating temp folder...\")\n",
    "temp_path = \"temp_train\"\n",
    "if os.path.exists(temp_path):\n",
    "    shutil.rmtree(temp_path)\n",
    "os.mkdir(temp_path)\n",
    "\n",
    "for p in paths:\n",
    "    shutil.copy(p, temp_path)\n",
    "print(\"Done.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " from temp_train.cgmml.common.model_utils.environment import cgm_environment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Connect to azure workspace.\n",
    "\n",
    "Make sure that you have a config.json file with the keys subscription_id, resource_group, and cgm-ml-dev. Either here (not so nice) or in a parent folder (okay but not perfect), or in the root folder of this repo (way to go)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "workspace = Workspace.from_config()\n",
    "workspace"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the experiment.\n",
    "\n",
    "- You should always arrange all your runs in an experiment.\n",
    "- Create at least one experiment per sprint.\n",
    "- Make sure that the name of the experiment reflects the sprint number.\n",
    "- On top of that you could also add other tokens to the name. For example network architecture, dataset name, and/or targets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "experiment = Experiment(workspace=workspace, name=experiment_name)\n",
    "experiment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find/create a compute target.\n",
    "\n",
    "Connects to a compute cluster on Azure ML.\n",
    "If the compute cluster does not exist, it will be created.\n",
    "\n",
    "Note: Usually computer clusters autoscale. This means that new nodes are created when necessary. And unused VMs will be shut down."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_name = CONFIG.CLUSTER_NAME\n",
    "\n",
    "# Compute cluster exists. Just connect to it.\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "\n",
    "# Compute cluster does not exist. Create one.    \n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC6', \n",
    "        max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "compute_target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the dataset for training.\n",
    "\n",
    "Here you specify which dataset to use.\n",
    "\n",
    "Note: Double check on Azure ML that you are using the right one."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = workspace.datasets[dataset_name]\n",
    "dataset"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Push the training source code to Azure.\n",
    "\n",
    "Creates an estimator (a template for a compute cluster node) and pushes it to the compute cluster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script_params = {f\"--{k}\": v for k, v in CONFIG.items()}\n",
    "script_params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cgm_env = cgm_environment(workspace=workspace,curated_env_name='cgm-env', env_exist=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if CONFIG.DATASET_MODE == DATASET_MODE_MOUNT:\n",
    "    dataset_argument = dataset.as_named_input('cgm_dataset').as_mount()\n",
    "elif CONFIG.DATASET_MODE == DATASET_MODE_DOWNLOAD:\n",
    "    dataset_argument = dataset.as_named_input('cgm_dataset').as_download()\n",
    "else:\n",
    "    raise Exception(\"Please specify DATASET_MODE\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the ScriptRunConfig\n",
    "script_run_config = ScriptRunConfig(source_directory=temp_path,\n",
    "                                    compute_target=compute_target,\n",
    "                                    script='train.py',\n",
    "                                    arguments=[dataset_argument] + [str(item) for sublist in script_params.items() for item in sublist],\n",
    "                                    environment=cgm_env,\n",
    ")\n",
    "\n",
    "# Set compute target.\n",
    "script_run_config.run_config.target = compute_target\n",
    "\n",
    "# Run the experiment.\n",
    "run = experiment.submit(config=script_run_config, tags=tags)\n",
    "\n",
    "# Show run.\n",
    "run"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Delete temp folder.\n",
    "\n",
    "After all code has been pushed to Azure ML, the temp folder will be removed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shutil.rmtree(temp_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}