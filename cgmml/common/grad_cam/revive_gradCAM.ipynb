{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.run import Run \n",
    "import sys\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob2 as glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from cgmml.common.evaluation.eval_utilities import download_model\n",
    "\n",
    "REPO_DIR = Path(os.getcwd()).parents[2].absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $PYTHONPATH\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(REPO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to azureml workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace.from_config()\n",
    "workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify experiment and run_id to download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"q3-depthmap-plaincnn-height-95k\"\n",
    "run_id = \"q3-depthmap-plaincnn-height-95k_1629821224_3ce63344\"  # Run 2\n",
    "input_location = 'outputs/best_model.ckpt'\n",
    "#input_location = 'outputs' # throws NameError: outputs's path extension not supported - from eval_utilities.py\n",
    "name = 'best_model.ckpt'\n",
    "#output_location = (REPO_DIR / 'data' / run_id)\n",
    "output_location = (REPO_DIR / 'data' / experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model(workspace=workspace, \n",
    "              experiment_name=experiment_name,\n",
    "              run_id=run_id,\n",
    "              input_location=input_location,\n",
    "              output_location=output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasmin/CGM_local/cgm-ml/data/q3-depthmap-plaincnn-height-95k/outputs/best_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model_file_path = (output_location / 'outputs' / 'best_model.ckpt' / 'saved_model.pb')\n",
    "model_file_path = (output_location / 'outputs' / 'best_model.ckpt')\n",
    "print(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt = tf.train.Checkpoint()\n",
    "#manager = tf.train.CheckpointManager(ckpt, model_file_path, max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt.restore(manager.latest_checkpoint)\n",
    "  #if manager.latest_checkpoint:\n",
    "#print(\"Restored from {}\".format(manager.latest_checkpoint))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_file_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 240, 180, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 180, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 120, 90, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 90, 64)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 120, 90, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 60, 45, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 45, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 22, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 22, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 15, 11, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,352,225\n",
      "Trainable params: 4,352,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume dataset and find some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALREADY DOWNLOADED\n",
    "#dataset = Dataset.get_by_name(workspace, name='anon-depthmap-mini')\n",
    "#dataset.download(target_path='./dataset', overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random examples out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_depthmap_files(paths):\n",
    "#    pickle_paths = []\n",
    "#    for path in paths:\n",
    "#        pickle_paths.extend(glob.glob(os.path.join(path, \"*.p\")))\n",
    "#    return pickle_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qrcode_paths: %d 1745\n",
      "./dataset/scans/1585361581-riv92cc0l8\n",
      "./dataset/scans/1585359783-15m68f6s91\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"./dataset/scans\"\n",
    "qrcode_paths = glob.glob(os.path.join(dataset_path, \"*\"))\n",
    "print('qrcode_paths: %d', len(qrcode_paths))\n",
    "print(qrcode_paths[0])\n",
    "print(qrcode_paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qrcode_paths_activation = random.choice(qrcode_paths)\n",
    "#qrcode_paths_activation = [qrcode_paths_activation]\n",
    "#print(len(qrcode_paths_activation))\n",
    "#print(qrcode_paths_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ./dataset/scans/1585273961-7dw2qedbor/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scantype_path = \"./dataset/scans/1585273961-7dw2qedbor/100/\"\n",
    "#print(scantype_path)\n",
    "#path_activate = get_depthmap_files(scantype_path)\n",
    "#print(len(path_activate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_paths = [\"./dataset/scans/1585273961-7dw2qedbor/100/pc_1585273961-7dw2qedbor_1592533886956_100_000.p\", \n",
    "              \"./dataset/scans/1585273961-7dw2qedbor/100/pc_1585273961-7dw2qedbor_1592533886956_100_014.p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pickle(path):\n",
    "    def find_max(path):\n",
    "        depthmap, targets = pickle.load(open(path.numpy(), \"rb\"))\n",
    "        depthmap = preprocess_depthmap(depthmap)\n",
    "        depthmax = tf.math.reduce_max(depthmap)\n",
    "        return depthmax\n",
    "    sample = []\n",
    "    depthmap_maximum = tf.py_function(find_max, [path], [tf.float32])\n",
    "    sample.append(depthmap_maximum)\n",
    "    return sample\n",
    "\n",
    "def preprocess_depthmap(depthmap):\n",
    "    # TODO here be more code.\n",
    "    return depthmap.astype(\"float32\")\n",
    "\n",
    "def preprocess_targets(targets, targets_indices):\n",
    "    if targets_indices is not None:\n",
    "        targets = targets[targets_indices]\n",
    "    return targets.astype(\"float32\")\n",
    "\n",
    "def get_max(dataset):\n",
    "    global_max = []\n",
    "    for value in dataset:\n",
    "        max_value = value[0].numpy()[0]\n",
    "        global_max.append(max_value)\n",
    "    max_array = np.array(global_max)\n",
    "    max_value = max_array.max()\n",
    "    return max_value\n",
    "\n",
    "def tf_load_pickle(path, max_value):\n",
    "    def py_load_pickle(path, max_value):\n",
    "        depthmap, targets = pickle.load(open(path.numpy(), \"rb\"))\n",
    "        depthmap = preprocess_depthmap(depthmap)\n",
    "        depthmap = depthmap / max_value\n",
    "        depthmap = tf.image.resize(depthmap, (image_target_height, image_target_width))\n",
    "        targets = preprocess_targets(targets, targets_indices)\n",
    "        return depthmap, targets\n",
    "\n",
    "    depthmap, targets = tf.py_function(py_load_pickle, [path, max_value], [tf.float32, tf.float32])\n",
    "    depthmap.set_shape((image_target_height, image_target_width, 1))\n",
    "    targets.set_shape((len(targets_indices,)))\n",
    "    return depthmap, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE REMOVE THIS, THIS IS BAD\n",
    "image_target_width = 180\n",
    "image_target_height = 240\n",
    "targets_indices = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-03 16:10:03.415005: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# understand better what happens here\n",
    "paths = scan_paths\n",
    "dataset_current = tf.data.Dataset.from_tensor_slices(paths)\n",
    "dataset_current = dataset_current.map(lambda path: calculate_pickle(path))\n",
    "dataset_max = get_max(dataset_current)\n",
    "#logger.info('Maximum value of activation dataset: %.2f', dataset_max)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(paths)\n",
    "dataset = dataset.map(lambda path: tf_load_pickle(path, dataset_max))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_activation = dataset\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_activation))\n",
    "print(type(dataset_activation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCAM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, layerName):\n",
    "        self.model = model\n",
    "        self.layerName = layerName\n",
    "\n",
    "        self.gradModel = Model(inputs=[self.model.inputs],\n",
    "                               outputs=[self.model.get_layer(self.layerName).output, model.output])\n",
    "\n",
    "    def compute_heatmap(self, image, classIdx, eps=1e-8):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            #tape.watch(self.gradModel.get_layer(self.layerName).output)\n",
    "            tape.watch(tf.convert_to_tensor(self.gradModel.get_layer(self.layerName).output))\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = self.gradModel(inputs)\n",
    "            if len(predictions) == 1:\n",
    "                loss = predictions[0]\n",
    "            else:\n",
    "                loss = predictions[:, classIdx]\n",
    "\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        heatmap = (heatmap * 255).astype(\"float32\")\n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate GradCAM class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last convolutional layer: conv2d_11 (Conv2D)           (None, 7, 5, 256)         590080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'conv2d_11'\n",
    "cam = GradCAM(model, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Passed in object of type <class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>, not tf.Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8v/1nfvbw9j4jx4hnpj95l552f40000gn/T/ipykernel_10735/3381476365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m## Compute Heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassIDx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#image = image.reshape(image.shape[1:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#image = image * 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8v/1nfvbw9j4jx4hnpj95l552f40000gn/T/ipykernel_10735/4238072670.py\u001b[0m in \u001b[0;36mcompute_heatmap\u001b[0;34m(self, image, classIdx, eps)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayerName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mconvOutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/py37-cgm/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    904\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         raise ValueError(\"Passed in object of type {}, not tf.Tensor\".format(\n\u001b[0;32m--> 906\u001b[0;31m             type(t)))\n\u001b[0m\u001b[1;32m    907\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         logging.log_first_n(\n",
      "\u001b[0;31mValueError\u001b[0m: Passed in object of type <class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>, not tf.Tensor"
     ]
    }
   ],
   "source": [
    "for data in dataset_activation:\n",
    "    image = data[0]\n",
    "    image = np.expand_dims(image, 0)\n",
    "    pred = model.predict(image)\n",
    "    classIDx = np.argmax(pred[0])\n",
    "    print(type(image))\n",
    "    print(type(classIDx))\n",
    "    \n",
    "    ## Compute Heatmap\n",
    "    heatmap = cam.compute_heatmap(image, classIDx)\n",
    "    #image = image.reshape(image.shape[1:])\n",
    "    #image = image * 255\n",
    "    #image = image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53cbebab1e12bd5adac4bb65b5ac2e11170cb1e4b68b2592d17c19e78095242"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
